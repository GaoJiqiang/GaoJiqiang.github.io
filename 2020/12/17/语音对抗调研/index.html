<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"gaojiqiang.github.io","root":"/","scheme":"Pisces","version":"8.0.2","exturl":false,"sidebar":{"position":"left","width":250,"display":"always","padding":10,"offset":12,"scrollpercent":true},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.json","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>

  <meta name="description" content="语音对抗调研前言相较于在图像上进行对抗攻击，对语音识别任务进行对抗攻击起步更晚，也更具有挑战性。原因在于语音识别极大依赖于语音信号数据中的频率和时序赖关系，在输入模型识别前需要对语音进行预处理和语音特征提取得到语音频谱图，图像上的对抗攻击可以利用给定可微损失函数的梯度来指导对抗搜索，但是语音上的损失标准一般不可分解，很难用梯度的方法去生成对抗样本。  下面说一下针对语音识别系统对抗攻击的几个标志性">
<meta property="og:type" content="article">
<meta property="og:title" content="语音对抗攻击">
<meta property="og:url" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/index.html">
<meta property="og:site_name" content="G Blog">
<meta property="og:description" content="语音对抗调研前言相较于在图像上进行对抗攻击，对语音识别任务进行对抗攻击起步更晚，也更具有挑战性。原因在于语音识别极大依赖于语音信号数据中的频率和时序赖关系，在输入模型识别前需要对语音进行预处理和语音特征提取得到语音频谱图，图像上的对抗攻击可以利用给定可微损失函数的梯度来指导对抗搜索，但是语音上的损失标准一般不可分解，很难用梯度的方法去生成对抗样本。  下面说一下针对语音识别系统对抗攻击的几个标志性">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-16-10-36-41.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-15-11-00-49.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-15-17-05-48.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-15-11-39-50.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-15-19-01-45.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-15-19-06-05.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-15-19-21-33.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-15-19-46-04.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-15-19-46-40.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-15-19-47-44.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-16-11-16-23.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-17-17-32-37.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-16-20-14-15.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-17-13-29-34.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-17-17-03-20.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-17-19-48-34.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-17-17-45-53.png">
<meta property="og:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB.png">
<meta property="article:published_time" content="2020-12-17T12:06:03.754Z">
<meta property="article:modified_time" content="2021-01-25T09:57:18.458Z">
<meta property="article:author" content="Jiqiang Gao">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/2020-12-16-10-36-41.png">


<link rel="canonical" href="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>语音对抗攻击 | G Blog</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">G Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Stay Hungry, Stay Foolish</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94"><span class="nav-number">1.</span> <span class="nav-text">语音对抗调研</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E6%A1%86%E6%9E%B6"><span class="nav-number">1.2.</span> <span class="nav-text">深度学习语音识别框架</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-end-to-end%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.2.1.</span> <span class="nav-text">1. end-to-end语音识别模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%9F%BA%E4%BA%8E%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E9%9F%B3%E7%B3%BB%E7%BB%9F"><span class="nav-number">1.2.2.</span> <span class="nav-text">2. 基于分类的语音系统</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E7%9B%AE%E5%89%8D%E5%90%84%E5%85%AC%E5%8F%B8%E4%BD%BF%E7%94%A8%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%EF%BC%9A"><span class="nav-number">1.2.3.</span> <span class="nav-text">3.目前各公司使用的一些语音识别系统：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86"><span class="nav-number">1.3.</span> <span class="nav-text">背景知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-CTC"><span class="nav-number">1.3.1.</span> <span class="nav-text">1. CTC</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%B9%E6%B3%95"><span class="nav-number">1.4.</span> <span class="nav-text">方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%BA%E6%99%AF"><span class="nav-number">1.4.1.</span> <span class="nav-text">场景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B7%E4%BD%93%E6%96%B9%E6%B3%95"><span class="nav-number">1.4.2.</span> <span class="nav-text">具体方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E7%9C%9F%E6%AD%A3%E6%84%8F%E4%B9%89%E4%B8%8A%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%AF%B9%E6%8A%97%E8%AF%AD%E9%9F%B3%E5%B7%A5%E4%BD%9C%EF%BC%9AAudio-Adversarial-Examples-Targeted-Attacks-on-Speech-to-Text-%E4%BD%9C%E8%80%85%E6%98%AFC-amp-W"><span class="nav-number">1.4.2.1.</span> <span class="nav-text">1. 真正意义上第一个对抗语音工作：Audio Adversarial Examples:Targeted Attacks on Speech-to-Text 作者是C&amp;W</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E4%B8%A4%E9%98%B6%E6%AE%B5%E4%BC%98%E5%8C%96%E6%B1%82%E8%A7%A3%E5%99%AA%E5%A3%B0%EF%BC%9ASirenAttack-Generating-Adversarial-Audio-for-End-to-End-Acoustic-Systems"><span class="nav-number">1.4.2.2.</span> <span class="nav-text">2. 两阶段优化求解噪声：SirenAttack: Generating Adversarial Audio for End-to-End Acoustic Systems</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E8%AE%BE%E8%AE%A1%E6%96%B0%E7%9A%84%E4%BB%A3%E7%90%86%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%9AHoudini-Fooling-Deep-Structured-Visual-and-Speech-Recognition-Models-with-Adversarial-Examples"><span class="nav-number">1.4.2.3.</span> <span class="nav-text">3. 设计新的代理损失函数：Houdini: Fooling Deep Structured Visual and Speech Recognition Models with Adversarial Examples</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E4%B8%8D%E5%8F%AF%E5%AF%9F%E8%A7%89-%E9%B2%81%E6%A3%92%EF%BC%9AImperceptible-Robust-and-Targeted-Adversarial-Examples-for-Automatic-Speech-Recognition"><span class="nav-number">1.4.2.4.</span> <span class="nav-text">4. 不可察觉+鲁棒：Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-%E7%99%BD%E7%9B%92%E9%B2%81%E6%A3%92%EF%BC%9ARobust-Audio-Adversarial-Example-for-a-Physical-Attack"><span class="nav-number">1.4.2.5.</span> <span class="nav-text">5. 白盒鲁棒：Robust Audio Adversarial Example for a Physical Attack</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-%E9%B2%81%E6%A3%92%EF%BC%9ATowards-Resistant-Audio-Adversarial-Examples"><span class="nav-number">1.4.2.6.</span> <span class="nav-text">6. 鲁棒：Towards Resistant Audio Adversarial Examples</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-%E9%BB%91%E7%9B%92%EF%BC%9ATargeted-Adversarial-Examples-for-Black-Box-Audio-Systems"><span class="nav-number">1.4.2.7.</span> <span class="nav-text">7. 黑盒：Targeted Adversarial Examples for Black Box Audio Systems</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-Cocaine-Noodles-Exploiting-the-Gap-between-Human-and-Machine-Speech-Recognition"><span class="nav-number">1.4.2.8.</span> <span class="nav-text">8. Cocaine Noodles: Exploiting the Gap between Human and Machine Speech Recognition</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-%E9%BB%91%E7%9B%92-amp-%E7%99%BD%E7%9B%92%EF%BC%9AHidden-Voice-Commands"><span class="nav-number">1.4.2.9.</span> <span class="nav-text">9. 黑盒&amp;白盒：Hidden Voice Commands</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-%E9%BB%91%E7%9B%92%EF%BC%9A%E2%80%9CDid-you-hear-that-Adversarial-Examples-Against-Automatic-Speech-Recognition-%E2%80%9D"><span class="nav-number">1.4.2.10.</span> <span class="nav-text">10. 黑盒：“Did you hear that? Adversarial Examples Against Automatic Speech Recognition,”</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-%E4%B8%8D%E5%8F%AF%E5%90%AC%E8%B6%85%E5%A3%B0%E6%B3%A2%E8%95%B4%E5%90%AB%E8%AF%AD%E4%B9%89%E4%BF%A1%E6%81%AF%EF%BC%9ADolphinAttack-Inaudible-Voice-Commands"><span class="nav-number">1.4.2.11.</span> <span class="nav-text">11. 不可听超声波蕴含语义信息：DolphinAttack: Inaudible Voice Commands</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-%E5%BF%83%E7%90%86%E5%A3%B0%E5%AD%A6%E6%A8%A1%E5%9E%8B%EF%BC%9AAdversarial-Attacks-Against-Automatic-Speech-Recognition-Systems-via-Psychoacoustic-Hiding"><span class="nav-number">1.4.2.12.</span> <span class="nav-text">12. 心理声学模型：Adversarial Attacks Against Automatic Speech Recognition Systems via Psychoacoustic Hiding</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#13-%E9%9F%B3%E4%B9%90-%E6%8C%87%E4%BB%A4%E9%9A%90%E8%97%8F%EF%BC%9ACommanderSong-A-Systematic-Approach-for-Practical-Adversarial-Voice-Recognition"><span class="nav-number">1.4.2.13.</span> <span class="nav-text">13 音乐+指令隐藏：CommanderSong: A Systematic Approach for Practical Adversarial Voice Recognition</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#14-Practical-Hidden-Voice-Attacks-against-Speech-and-Speaker-Recognition-Systems"><span class="nav-number">1.4.2.14.</span> <span class="nav-text">14. Practical Hidden Voice Attacks against Speech and Speaker Recognition Systems</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#15-Hear-%E2%80%9CNo-Evil%E2%80%9D-See-%E2%80%9CKenansville%E2%80%9D-Efficient-and-Transferable-Black-Box-Attacks-on-Speech-Recognition-and-Voice-Identification-Systems"><span class="nav-number">1.4.2.15.</span> <span class="nav-text">15. Hear “No Evil”, See “Kenansville”: Efficient and Transferable Black-Box Attacks on Speech Recognition and Voice Identification Systems.</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#16-The-Faults-in-our-ASRs-An-Overview-of-Attacks-against-Automatic-Speech-Recognition-and-Speaker-Identification-Systems"><span class="nav-number">1.4.2.16.</span> <span class="nav-text">16. The Faults in our ASRs: An Overview of Attacks against Automatic Speech Recognition and Speaker Identification Systems</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">1.5.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E5%BC%80%E6%BA%90%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">1.6.</span> <span class="nav-text">一些开源的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Audio-Adversarial-Examples-Paper-List"><span class="nav-number">1.6.1.</span> <span class="nav-text">Audio Adversarial Examples Paper List</span></a></li></ol></li></ol></li></ol></div>
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Jiqiang Gao"
      src="/images/icon.jpg">
  <p class="site-author-name" itemprop="name">Jiqiang Gao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/GaoJiqiang" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;GaoJiqiang" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:617624576@qq.com" title="E-Mail → mailto:617624576@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



        </section>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://gaojiqiang.github.io/2020/12/17/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E8%B0%83%E7%A0%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/icon.jpg">
      <meta itemprop="name" content="Jiqiang Gao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="G Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          语音对抗攻击
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-12-17 20:06:03" itemprop="dateCreated datePublished" datetime="2020-12-17T20:06:03+08:00">2020-12-17</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-01-25 17:57:18" itemprop="dateModified" datetime="2021-01-25T17:57:18+08:00">2021-01-25</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/secure-ML-Audio/" itemprop="url" rel="index"><span itemprop="name">secure ML, Audio</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="语音对抗调研"><a href="#语音对抗调研" class="headerlink" title="语音对抗调研"></a>语音对抗调研</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>相较于在图像上进行对抗攻击，对语音识别任务进行对抗攻击起步更晚，也更具有挑战性。原因在于语音识别极大依赖于语音信号数据中的频率和时序赖关系，在输入模型识别前需要对语音进行预处理和语音特征提取得到语音频谱图，图像上的对抗攻击可以利用给定可微损失函数的梯度来指导对抗搜索，但是语音上的损失标准一般不可分解，很难用梯度的方法去生成对抗样本。</p>
<p><img src="2020-12-16-10-36-41.png"></p>
<p>下面说一下针对语音识别系统对抗攻击的几个标志性工作：</p>
<p>2015年，Vaidya等人首次尝试针对语音识别系统的扰动攻击，在语音识别系统与处理环节中的特征提取步骤修改输入语音信号，生成人耳无法辨别但能被云隐识别系统正确识别的语音信号，但是实际扰动较大，效果并不好。</p>
<p>2016年，Calini等人提出了“隐藏语音指令”攻击，设计了基于梯度优化的生成对抗扰动的方法，为了在音频信号特征提取后依然保持对抗性，采用了逆语音特征提取的方法反向得到音频信号。但同样容易被人耳感知。</p>
<p>2017年，zhang等人提出了“海豚音攻击”。为了让攻击不被人耳察觉，将对抗扰动频率提高到了20Khz以上，虽然不容易被人耳察觉，但是很溶剂被过滤和检测，此外，还需要特定设备发射播放得到超声信号。</p>
<p>2018年，Calini和Wagner在流行的语音识别系统DeepSpeech上生成了实际意义的对抗样本，借鉴了图像分类的C&amp;W攻击方法并在目标函数中使用了深度学习语音识别模型特有的CTC损失函数。使修改后的音频不易被人耳察觉，同时也能使基于深度学习的识别系统错误识别。但是在噪声环境下鲁棒性较差。</p>
<p>ps：2018年之前的工作不能称为真正意义上的对抗性样本，因为生成的音频对原始语音的扰动太大，人很容易意识到语音被篡改，并且攻击的语音模型不是基于深度学习训练得到的。</p>
<h2 id="深度学习语音识别框架"><a href="#深度学习语音识别框架" class="headerlink" title="深度学习语音识别框架"></a>深度学习语音识别框架</h2><h3 id="1-end-to-end语音识别模型"><a href="#1-end-to-end语音识别模型" class="headerlink" title="1. end-to-end语音识别模型"></a>1. end-to-end语音识别模型</h3><p>输入一段.wav格式的音频识别步骤：</p>
<blockquote>
<p>1）预处理：会进行解码、降噪等操作，把音频分成较短的帧；<br>2）特征提取：从短帧中提取声学特征，常用MFCC特征(梅尔倒谱系数);<br>3）基于模型的预测：将声学特征作为输入数据，生成预测结果，主流系统通常使用RNNs+CTC损失函数模型<br><img src="2020-12-15-11-00-49.png"></p>
</blockquote>
<p>这里有两个地方需要进行了解:<br>一个是<strong>CTC</strong>函数，是一种声学模型，CTC-Loss函数，在设计语音对抗样本Loss函数时可能需要用到；一个是<strong>MFCC</strong>，了解语音信息的特征提取过程，便于设计对抗生成方法。</p>
<h3 id="2-基于分类的语音系统"><a href="#2-基于分类的语音系统" class="headerlink" title="2. 基于分类的语音系统"></a>2. 基于分类的语音系统</h3><blockquote>
<p>1）预处理：同上；<br>2）特征提取：一般用CNNs提取audio-level feature和frame-level feature<br>3）基于模型的预测：将声学特征作为输入数据，生成预测结果，模型通常用CNNs<br><img src="2020-12-15-17-05-48.png"></p>
</blockquote>
<h3 id="3-目前各公司使用的一些语音识别系统："><a href="#3-目前各公司使用的一些语音识别系统：" class="headerlink" title="3.目前各公司使用的一些语音识别系统："></a>3.目前各公司使用的一些语音识别系统：</h3><p><img src="2020-12-15-11-39-50.png"></p>
<h2 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h2><h3 id="1-CTC"><a href="#1-CTC" class="headerlink" title="1. CTC"></a>1. CTC</h3><p>CTC是一种RNN的端到端训练方法，可以让RNN直接对序列数据进行学习，而无需事先标注好训练数据中输入序列和输出序列的映射关系。音频数据很难像文本那样进行分割，因此无法直接使用RNN进行训练。</p>
<blockquote>
<p>给定输入序列 X={x1,x2,……xT}以及对应的标签数据 Y={y1,y2,……yU}，目的是找到X到Y的一个映射，这种对时序数据进行分类的算法叫做Temporal Classification。</p>
</blockquote>
<p>CTC提供了解决方案，对于一个给定的输入序列 X ，CTC给出所有可能的 Y 的输出分布。根据这个分布，我们可以输出最可能的结果或者给出某个输出的概率。 $Y^*=argmax_yP(Y|X)$</p>
<p><strong>1.1 对齐</strong></p>
<p>在CTC中，多个输出路径会对应一个输出结果，输入X是”CAT”的语音，输出Y是文本[C,A,T],音频做切割后，每个时间片得到一个输出。因此X和Y之间的映射是多对一的，在对齐时要考虑<strong>去重</strong>和引入<strong>空白字符</strong>。</p>
<ul>
<li>HHHEE_LL_LLLOOO    去重</li>
<li>HE_L_LO            去除空白字符</li>
<li>HELLO 完成     </li>
</ul>
<p><strong>1.2 CTC loss数学推导</strong></p>
<p>略，太长只过了一遍<br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/shiyublog/p/10493348.html">https://www.cnblogs.com/shiyublog/p/10493348.html</a></p>
<p><strong>1.3 结果搜索</strong></p>
<p>贪心搜索是选取每一帧预测概率最大的那一项作为结果，此外还有束搜索，和基于动态规划的搜索。</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h3><p><strong>1. speech-to-text</strong></p>
<table>
<thead>
<tr>
<th>input</th>
<th>output</th>
</tr>
</thead>
<tbody><tr>
<td>正常语音+扰动</td>
<td>目标语义</td>
</tr>
<tr>
<td>正常语音+扰动</td>
<td>空语义</td>
</tr>
<tr>
<td>随机噪音+扰动</td>
<td>目标语义</td>
</tr>
</tbody></table>
<p><strong>2. speech commands classification</strong></p>
<table>
<thead>
<tr>
<th>input</th>
<th>output</th>
</tr>
</thead>
<tbody><tr>
<td>正常语音+扰动</td>
<td>目标分类</td>
</tr>
<tr>
<td>正常语音+扰动</td>
<td>随机分类</td>
</tr>
<tr>
<td>随机噪音+扰动</td>
<td>目标分类</td>
</tr>
</tbody></table>
<p>18年之前的工作基本都是基于传统的语音模型（非神经网络）来做的，或是需要生成全新的音频，例如一段音乐隐藏语音指令这种，不能实现类似于图像对抗中与源数据不可区分的效果；</p>
<blockquote>
<p><em>Hidden voice commands.<br>Dolphinattack: Inaudible voice commands.<br>Inaudible voice commands.</em> </p>
</blockquote>
<p>同时期另一条研究线路能够做到于源数据几乎不可区分的untarget攻击；</p>
<blockquote>
<p><em>Crafting adversarial examples for speech paralinguistics applications.<br>Houdini: Fooling deep structured prediction models.</em></p>
</blockquote>
<p>2018年Carlini &amp; Wagner实现了针对任意多词句子的语音识别系统构建了对抗样本，但不能在real world有效。同年CommanderSong开发出了在real world有效的对抗样本，但代价是给原始音频引入了明显的扰动。</p>
<blockquote>
<p><em>Audio adversarial examples: Targeted attacks on speech-to-text.<br>Commandersong: A systematic approach for practical adversarial voice recognition.</em></p>
</blockquote>
<p>此后，一些工作开发了对深度学习ASR系统的攻击，要么在real world中工作，要么不那么明显地被察觉</p>
<blockquote>
<p><em>Robust audio adversarial example for a physical attack.<br>Adversarial attacks against automatic speech recognition systems via psychoacoustic hiding.</em></p>
</blockquote>
<p>在后面，就是一些将白盒设置转为黑盒设置的一些工作</p>
<blockquote>
<p><em>Adversarial blackbox attacks for automatic speech recognition systems using multi-objective genetic optimization.<br>Targeted adversarial examples for black box audio systems.</em></p>
</blockquote>
<h3 id="具体方法"><a href="#具体方法" class="headerlink" title="具体方法"></a>具体方法</h3><p>直觉是直接使用图像中生成对抗样本的算法，例如FGSM、DeepFool、PGD等等，但是这些方法在语音对抗样本生成过程中都不好用。因此需要新的算法设计。</p>
<h4 id="1-真正意义上第一个对抗语音工作：Audio-Adversarial-Examples-Targeted-Attacks-on-Speech-to-Text-作者是C-amp-W"><a href="#1-真正意义上第一个对抗语音工作：Audio-Adversarial-Examples-Targeted-Attacks-on-Speech-to-Text-作者是C-amp-W" class="headerlink" title="1. 真正意义上第一个对抗语音工作：Audio Adversarial Examples:Targeted Attacks on Speech-to-Text 作者是C&amp;W"></a>1. 真正意义上第一个对抗语音工作：Audio Adversarial Examples:Targeted Attacks on Speech-to-Text 作者是C&amp;W</h4><p><a target="_blank" rel="noopener" href="https://github.com/carlini/audio_adversarial_examples">https://github.com/carlini/audio_adversarial_examples</a></p>
<blockquote>
<p>白盒场景下，针对百度DeepSpeech迭代优化攻击。给定任意音频波形，可以产生99.99%相似的另一个音频，且可以转录为所选择的任何短语。<br>算法：借鉴了图像对抗样本中的C&amp;W方法，将对抗语音生成问题首次转换为了优化问题，并首次在语音对抗样本生成目标函数中引入了深度学习语音识别模型特有的CTC损失函数。</p>
</blockquote>
<table>
<thead>
<tr>
<th>Initial</th>
<th>Reformulation</th>
<th>Solve $l_{\infty}$  without converge</th>
</tr>
</thead>
<tbody><tr>
<td><img src="2020-12-15-19-01-45.png"></td>
<td><img src="2020-12-15-19-06-05.png"></td>
<td><img src="2020-12-15-19-21-33.png"></td>
</tr>
</tbody></table>
<p>在这里设$l(x’,t)=CTC-Loss(x’,t)$，</p>
<p><strong>Improved loss function：</strong></p>
<table>
<thead>
<tr>
<th><img src="2020-12-15-19-46-04.png"></th>
<th><img src="2020-12-15-19-46-40.png"></th>
<th><img src="2020-12-15-19-47-44.png"></th>
</tr>
</thead>
</table>
<p>本文在improved loss中说明攻击方法只能在 DeepSpeech 使用 Greedy-Search 的情况下有效。</p>
<ul>
<li><strong>Demo</strong></li>
</ul>
<table>
<thead>
<tr>
<th>Status</th>
<th>Audio</th>
<th>Transcription</th>
</tr>
</thead>
<tbody><tr>
<td>original</td>
<td><audio id="audio" controls="" preload="none"><source id="mp3" src="https://nicholas.carlini.com/code/audio_adversarial_examples/adversarial0.wav"></audio></td>
<td>without the dataset the article is useless</td>
</tr>
<tr>
<td>adversarial</td>
<td><audio id="audio" controls="" preload="none"><source id="mp3" src="https://nicholas.carlini.com/code/audio_adversarial_examples/adversarial0.wav"></audio></td>
<td>okay google browse to evil dot com</td>
</tr>
</tbody></table>
<h4 id="2-两阶段优化求解噪声：SirenAttack-Generating-Adversarial-Audio-for-End-to-End-Acoustic-Systems"><a href="#2-两阶段优化求解噪声：SirenAttack-Generating-Adversarial-Audio-for-End-to-End-Acoustic-Systems" class="headerlink" title="2. 两阶段优化求解噪声：SirenAttack: Generating Adversarial Audio for End-to-End Acoustic Systems"></a>2. 两阶段优化求解噪声：SirenAttack: Generating Adversarial Audio for End-to-End Acoustic Systems</h4><blockquote>
<p>白盒：第一阶段先利用粒子群算法(PSO)求出粗粒度的噪声$\delta$,第二阶段再利用CTC-loss反馈的梯度信息使用Fooling Gradient方法对其矫正求出更精确的$\delta$。<br>   黑盒：由于没有loss信息，所以在第一阶段引入模型置信度量，引导粒子群向更优方向迭代，效果有限。</p>
</blockquote>
<p>亮点：涉及到了黑盒、计算效率高生成时间段、攻击测试了多个主流的语音识别模型</p>
<h4 id="3-设计新的代理损失函数：Houdini-Fooling-Deep-Structured-Visual-and-Speech-Recognition-Models-with-Adversarial-Examples"><a href="#3-设计新的代理损失函数：Houdini-Fooling-Deep-Structured-Visual-and-Speech-Recognition-Models-with-Adversarial-Examples" class="headerlink" title="3. 设计新的代理损失函数：Houdini: Fooling Deep Structured Visual and Speech Recognition Models with Adversarial Examples"></a>3. 设计新的代理损失函数：Houdini: Fooling Deep Structured Visual and Speech Recognition Models with Adversarial Examples</h4><p>解决了对抗样本生成中评价指标存在组合及不可谓的问题，如语音识别中常用word error rate来评价，其就是不可微的。文章中提到，虽然CTC针对语音识别任务是一种可微的代理损失函数，但是针对其他结构性任务（如语义分割、姿态估计等）并没有一致性保证。本文实际是提出了一种针对类似不可微问题下生成对抗样本的框架。</p>
<p>文章提出了一种Houdini代理损失函数，可以用来针对结构性任务生成对抗样本：<br><img src="2020-12-16-11-16-23.png"></p>
<p>文章中还对基于Houdini和CTC两种损失函数生成的对抗样本进行了比较，结果显示Houdini要优于CTC，但是target攻击效果并不好。 ps:由于遇到MFC层反向传播的困难，因此攻击只能生成音谱对抗数据，不能直接生成audio，工作1解决了这个问题。</p>
<h4 id="4-不可察觉-鲁棒：Imperceptible-Robust-and-Targeted-Adversarial-Examples-for-Automatic-Speech-Recognition"><a href="#4-不可察觉-鲁棒：Imperceptible-Robust-and-Targeted-Adversarial-Examples-for-Automatic-Speech-Recognition" class="headerlink" title="4. 不可察觉+鲁棒：Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition"></a>4. 不可察觉+鲁棒：Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition</h4><ul>
<li>白盒、有目标的、针对端到端LAS模型的对抗攻击算法；</li>
<li>心里掩蔽效应</li>
<li>模拟房间声学响应</li>
</ul>
<p>亮点在于优化语音对抗输入使其对人耳不可分辨，且更加Robust，首次在real world中产生有效攻击。提出了非基于$l_p$的对抗样本构造方法。</p>
<p>不可察觉：文中未使用$l_p$失真度量，而是依赖于构建<strong>心理学模型</strong>使得对抗语音难以察觉：<strong>频率掩蔽</strong>通过使用另外一种充当“掩蔽器”的信号对对抗性样本进行掩护，实质是在人类听不到音频区域添加对抗扰动。优化分为两阶段，首先寻找一个相对较小的的扰动欺骗网络（和C&amp;W工作相同），再去优化对抗样本使其不易察觉。</p>
<p>物理世界可用：考虑在训练时引入随机房间环境模拟器，考虑现实环境中的影响，实验只在模拟环境下有效。带混响的优化。</p>
<p>最后算法将两个目标结合，设计了优化损失函数。</p>
<h4 id="5-白盒鲁棒：Robust-Audio-Adversarial-Example-for-a-Physical-Attack"><a href="#5-白盒鲁棒：Robust-Audio-Adversarial-Example-for-a-Physical-Attack" class="headerlink" title="5. 白盒鲁棒：Robust Audio Adversarial Example for a Physical Attack"></a>5. 白盒鲁棒：Robust Audio Adversarial Example for a Physical Attack</h4><p><a target="_blank" rel="noopener" href="https://github.com/hiromu/robust_audio_ae">https://github.com/hiromu/robust_audio_ae</a></p>
<p>亮点：引入脉冲响应，首次实现了pysical下的对抗样本攻击，直接思路就是讲环境带来的扰动提前考虑进来，用到了三个技术：</p>
<ul>
<li>Band-pass Filter：麦克风会去除环境中的一些杂音，若对抗扰动超出范围，则会被剪切，因此在损失函数中讲对抗扰动固定在不会被剪切的一个范围。</li>
<li>Impulse Response：将环境中的脉冲响应考虑进损失函数，增强对抗语音在使用中对混响的鲁棒性。</li>
<li>White Gaussian Noise：模拟环境中许多自然产生的背景噪声</li>
</ul>
<h4 id="6-鲁棒：Towards-Resistant-Audio-Adversarial-Examples"><a href="#6-鲁棒：Towards-Resistant-Audio-Adversarial-Examples" class="headerlink" title="6. 鲁棒：Towards Resistant Audio Adversarial Examples"></a>6. 鲁棒：Towards Resistant Audio Adversarial Examples</h4><p>考虑实际场景下播放器和麦克风之间距离引起的位移偏差，在优化对抗数据时加入偏差因素，使得最终的对抗语音具有较好的鲁棒性。</p>
<h4 id="7-黑盒：Targeted-Adversarial-Examples-for-Black-Box-Audio-Systems"><a href="#7-黑盒：Targeted-Adversarial-Examples-for-Black-Box-Audio-Systems" class="headerlink" title="7. 黑盒：Targeted Adversarial Examples for Black Box Audio Systems"></a>7. 黑盒：Targeted Adversarial Examples for Black Box Audio Systems</h4><p>code：<a target="_blank" rel="noopener" href="https://github.com/rtaori/Black-Box-Audio">https://github.com/rtaori/Black-Box-Audio</a></p>
<ul>
<li>黑盒、有目标的攻击DeepSpeech的对抗攻击算法</li>
<li>两阶段方法：遗传（改进引入Momentum mutation）+梯度估计</li>
<li>问题：出现了query次数巨大的问题，适用场景有限</li>
</ul>
<h4 id="8-Cocaine-Noodles-Exploiting-the-Gap-between-Human-and-Machine-Speech-Recognition"><a href="#8-Cocaine-Noodles-Exploiting-the-Gap-between-Human-and-Machine-Speech-Recognition" class="headerlink" title="8. Cocaine Noodles: Exploiting the Gap between Human and Machine Speech Recognition"></a>8. Cocaine Noodles: Exploiting the Gap between Human and Machine Speech Recognition</h4><ul>
<li>攻击特征模块</li>
<li>思路简单，提取MFCC特征（这个过程会丢失一些语音信息），然后把MFCC特征逆转为语音信号</li>
<li>算法描述不清晰，如何对MFCC逆转没过多提及。</li>
</ul>
<p><img src="2020-12-17-17-32-37.png"></p>
<h4 id="9-黑盒-amp-白盒：Hidden-Voice-Commands"><a href="#9-黑盒-amp-白盒：Hidden-Voice-Commands" class="headerlink" title="9. 黑盒&amp;白盒：Hidden Voice Commands"></a>9. 黑盒&amp;白盒：Hidden Voice Commands</h4><p>黑盒下生成一段无关的音频，其中隐藏有语音指令，本质上还不能称之为对抗语音，因为生成的音频不是不可察觉的。</p>
<ul>
<li>是对Cocaine Noodles的完善</li>
<li>攻击特征提取模块</li>
<li>使用梯度下降算法攻击GMM-HMM模型</li>
<li>从这篇开始语音对抗有了比较清晰的思路，calini还是很有经验的。</li>
</ul>
<p><img src="2020-12-16-20-14-15.png"></p>
<p>比较关键的是MFCC parameter和inverse MFCC这两步。计算MFCC然后逆转为时域信号的过程，能够从理论上保留<strong>语音识别算法关注的特征，而抹除不想管的语音特征</strong>，而抹除的这部分特征又很可能是对人的听觉影响是很大的，导致人无法听清对抗样本。</p>
<h4 id="10-黑盒：“Did-you-hear-that-Adversarial-Examples-Against-Automatic-Speech-Recognition-”"><a href="#10-黑盒：“Did-you-hear-that-Adversarial-Examples-Against-Automatic-Speech-Recognition-”" class="headerlink" title="10. 黑盒：“Did you hear that? Adversarial Examples Against Automatic Speech Recognition,”"></a>10. 黑盒：“Did you hear that? Adversarial Examples Against Automatic Speech Recognition,”</h4><p><a target="_blank" rel="noopener" href="https://github.com/nesl/adversarial_audio">https://github.com/nesl/adversarial_audio</a></p>
<p>场景是语音分类场景下的对抗样本攻击，攻击目标是ASR，指出语音对抗样本无法适用基于梯度的优化迭代方法，使用了<strong>遗传算法</strong>。</p>
<img src="2020-12-17-13-29-34.png" width="60%" height="60%">

<h4 id="11-不可听超声波蕴含语义信息：DolphinAttack-Inaudible-Voice-Commands"><a href="#11-不可听超声波蕴含语义信息：DolphinAttack-Inaudible-Voice-Commands" class="headerlink" title="11. 不可听超声波蕴含语义信息：DolphinAttack: Inaudible Voice Commands"></a>11. 不可听超声波蕴含语义信息：DolphinAttack: Inaudible Voice Commands</h4><p>海豚音攻击：利用麦克风的非线性来用高于20 kHz的超声波调节基带音频信号，可以隐藏转录。让正常的语音隐藏到高频波段中，从而让其无法被听到。</p>
<p><strong>实质上是利用了麦克风的非线性漏洞，使得高频信号采样后出现额外的低频分量</strong></p>
<h4 id="12-心理声学模型：Adversarial-Attacks-Against-Automatic-Speech-Recognition-Systems-via-Psychoacoustic-Hiding"><a href="#12-心理声学模型：Adversarial-Attacks-Against-Automatic-Speech-Recognition-Systems-via-Psychoacoustic-Hiding" class="headerlink" title="12. 心理声学模型：Adversarial Attacks Against Automatic Speech Recognition Systems via Psychoacoustic Hiding"></a>12. 心理声学模型：Adversarial Attacks Against Automatic Speech Recognition Systems via Psychoacoustic Hiding</h4><p>介绍了一种基于心理声学隐藏的攻击ASR系统的新型对抗样本。利用如MP3编码中的心理声学建模，以减少可察觉的噪音。</p>
<ul>
<li>白盒、有目标的、针对DNN-HMM模型的对抗攻击算法</li>
<li>首次提出使用升学掩蔽效应</li>
</ul>
<p><img src="2020-12-17-17-03-20.png"></p>
<p>example：黑色为1Khz处60db的能量掩蔽曲线</p>
<h4 id="13-音乐-指令隐藏：CommanderSong-A-Systematic-Approach-for-Practical-Adversarial-Voice-Recognition"><a href="#13-音乐-指令隐藏：CommanderSong-A-Systematic-Approach-for-Practical-Adversarial-Voice-Recognition" class="headerlink" title="13 音乐+指令隐藏：CommanderSong: A Systematic Approach for Practical Adversarial Voice Recognition"></a>13 音乐+指令隐藏：CommanderSong: A Systematic Approach for Practical Adversarial Voice Recognition</h4><p>在歌曲中加入语音命令，通过播放歌曲实施攻击</p>
<h4 id="14-Practical-Hidden-Voice-Attacks-against-Speech-and-Speaker-Recognition-Systems"><a href="#14-Practical-Hidden-Voice-Attacks-against-Speech-and-Speaker-Recognition-Systems" class="headerlink" title="14. Practical Hidden Voice Attacks against Speech and Speaker Recognition Systems"></a>14. Practical Hidden Voice Attacks against Speech and Speaker Recognition Systems</h4><ul>
<li>Hidden voice的黑盒扩展，将正常语音模糊化，攻击特征提取模块</li>
<li>体现出语音攻击在物理、黑盒环境下的挑战是很大的</li>
</ul>
<h4 id="15-Hear-“No-Evil”-See-“Kenansville”-Efficient-and-Transferable-Black-Box-Attacks-on-Speech-Recognition-and-Voice-Identification-Systems"><a href="#15-Hear-“No-Evil”-See-“Kenansville”-Efficient-and-Transferable-Black-Box-Attacks-on-Speech-Recognition-and-Voice-Identification-Systems" class="headerlink" title="15. Hear “No Evil”, See “Kenansville”: Efficient and Transferable Black-Box Attacks on Speech Recognition and Voice Identification Systems."></a>15. Hear “No Evil”, See “Kenansville”: Efficient and Transferable Black-Box Attacks on Speech Recognition and Voice Identification Systems.</h4><p><a target="_blank" rel="noopener" href="https://github.com/kwarren9413/kenansville_attack">https://github.com/kwarren9413/kenansville_attack</a></p>
<ul>
<li>声称能做到近实时、黑盒、可迁移欺骗ASR，对抗语音几乎不会误导人耳，但是会产生非目标识别错误</li>
<li>可以大大减少黑盒攻击下query的次数</li>
<li>不是基于梯度来做的</li>
</ul>
<p><img src="2020-12-17-19-48-34.png"></p>
<p>signal decomposition用的是DFT or SSA，没用MFCC，步骤也比较简单，就是设置阈值对信号进行截断，在不影响人耳识别的情况下，尽可能欺骗ASR。由于不涉及梯度，所以可以看作是黑盒的。</p>
<h4 id="16-The-Faults-in-our-ASRs-An-Overview-of-Attacks-against-Automatic-Speech-Recognition-and-Speaker-Identification-Systems"><a href="#16-The-Faults-in-our-ASRs-An-Overview-of-Attacks-against-Automatic-Speech-Recognition-and-Speaker-Identification-Systems" class="headerlink" title="16. The Faults in our ASRs: An Overview of Attacks against Automatic Speech Recognition and Speaker Identification Systems"></a>16. The Faults in our ASRs: An Overview of Attacks against Automatic Speech Recognition and Speaker Identification Systems</h4><blockquote>
<p>2021年 S&amp;P的一篇综述：（Hadi Abdullah在audio攻击有若干工作）下图是总结了已有攻击的各个维度的对比。</p>
</blockquote>
<p><img src="2020-12-17-17-45-53.png"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>对语音识别系统做对抗样本攻击，首先要了解语音模型的识别流程，重点是特征提取的CTC步骤，然后在黑盒下要注意使用遗传算法，同时，要做到现实可用且不可察觉两点要求。基于上述的攻击目标，目前的工作基本只能完成其中几项，且实验条件苛刻。   </p>
<p><img src="%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB.png"></p>
<h2 id="一些开源的实现"><a href="#一些开源的实现" class="headerlink" title="一些开源的实现"></a>一些开源的实现</h2><h3 id="Audio-Adversarial-Examples-Paper-List"><a href="#Audio-Adversarial-Examples-Paper-List" class="headerlink" title="Audio Adversarial Examples Paper List"></a>Audio Adversarial Examples Paper List</h3><table>
<thead>
<tr>
<th>Title</th>
<th>Authors</th>
<th>Publication</th>
<th>Year</th>
<th>Code</th>
<th>Demo</th>
<th>Presentation</th>
</tr>
</thead>
<tbody><tr>
<td><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1708.07238">Inaudible Voice Commands</a></td>
<td>L. Song et al.</td>
<td>CCS</td>
<td>2017</td>
<td><a target="_blank" rel="noopener" href="https://github.com/lwsong/inaudible-voice-commands">☑️</a></td>
<td><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=wF-DuVkQNQQ">☑️</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1801.01944">Audio Adversarial Examples: Targeted Attacks on Speech-to-Text</a></td>
<td>N. Carlini et al.</td>
<td>DLS</td>
<td>2018</td>
<td><a target="_blank" rel="noopener" href="https://github.com/carlini/audio_adversarial_examples">☑️</a></td>
<td><a target="_blank" rel="noopener" href="https://nicholas.carlini.com/code/audio_adversarial_examples/">☑️</a></td>
<td><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=Ho5jLKfoKSA">☑️</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1805.11852">ADAGIO: Interactive Experimentation with Adversarial Attack and Defense for Audio</a></td>
<td>N. Das et al.</td>
<td>ECML-PKDD</td>
<td>2018</td>
<td></td>
<td><a target="_blank" rel="noopener" href="https://youtu.be/0W2BKMwSfVQ">☑️</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://www.usenix.org/conference/usenixsecurity18/presentation/yuan-xuejing">CommanderSong: A Systematic Approach for Practical Adversarial Voice Recognition</a></td>
<td>X. Yuan et al.</td>
<td>USENIX Security</td>
<td>2018</td>
<td></td>
<td></td>
<td><a target="_blank" rel="noopener" href="https://www.usenix.org/conference/usenixsecurity18/presentation/yuan-xuejing">☑️</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1811.01312">Adversarial Black-Box Attacks for Automatic Speech Recognition Systems Using Multi-Objective Genetic Optimization</a></td>
<td>S. Khare et al.</td>
<td>Interspeech</td>
<td>2019</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1808.05665">Adversarial Attacks Against Automatic Speech Recognition Systems via Psychoacoustic Hiding</a></td>
<td>L. Schönherr et al.</td>
<td>NDSS</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://github.com/rub-ksv/adversarialattacks">☑️</a></td>
<td><a target="_blank" rel="noopener" href="https://adversarial-attacks.net/">☑️</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1810.11793">Robust Audio Adversarial Example for a Physical Attack</a></td>
<td>H. Yakura et al.</td>
<td>IJCAI</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://github.com/hiromu/robust_audio_ae">☑️</a></td>
<td><a target="_blank" rel="noopener" href="https://yumetaro.info/projects/audio-ae/">☑️</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1809.10875">Characterizing Audio Adversarial Examples Using Temporal Dependency</a></td>
<td>Z. Yang et al.</td>
<td>ICLR</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://github.com/AI-secure/Characterizing-Audio-Adversarial-Examples-using-Temporal-Dependency">☑️</a></td>
<td><a target="_blank" rel="noopener" href="https://www.ibm.com/blogs/research/2019/05/audio-adversarial-attacks/">☑️</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1904.05734">Practical Hidden Voice Attacks against Speech and Speaker Recognition Systems</a></td>
<td>H. Abdullah et al.</td>
<td>NDSS</td>
<td>2019</td>
<td></td>
<td><a target="_blank" rel="noopener" href="https://sites.google.com/view/transcript-evasion">☑️</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1910.05262">Hear ‘No Evil’, See ‘Kenansville’: Efficient and Transferable Black-Box Attacks on Speech Recognition and Voice Identification Systems</a></td>
<td>H. Abdullah et al.</td>
<td>arXiv</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://github.com/hamzayacoob/VPSesAttacks">☑️</a></td>
<td><a target="_blank" rel="noopener" href="https://sites.google.com/view/transcript-evasion">☑️</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1901.07846">SirenAttack: Generating Adversarial Audio for End-to-End Acoustic Systems</a></td>
<td>T. Du et al.</td>
<td>NDSS</td>
<td>2019</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1901.10300">Towards Weighted-Sampling Audio Adversarial Example Attack</a></td>
<td>X. Liu et al.</td>
<td>AAAI</td>
<td>2019</td>
<td></td>
<td><a target="_blank" rel="noopener" href="https://sites.google.com/view/audio-adversarial-examples">☑️</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1905.03828">Universal Adversarial Perturbations for Speech Recognition Systems</a></td>
<td>P. Neekharaet al.</td>
<td>Interspeech</td>
<td>2019</td>
<td></td>
<td><a target="_blank" rel="noopener" href="https://universal-audio-perturbation.herokuapp.com/index.html">☑️</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1903.10346">Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition</a></td>
<td>Y. Qin et al.</td>
<td>ICML</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://github.com/tensorflow/cleverhans/tree/master/examples/adversarial_asr">☑️</a></td>
<td><a target="_blank" rel="noopener" href="http://cseweb.ucsd.edu/~yaq007/imperceptible-robust-adv.html">☑️</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1908.01551">Imperio: Robust Over-the-Air Adversarial Examples for Automatic Speech Recognition Systems</a></td>
<td>L. Schönherr et al.</td>
<td>arXiv</td>
<td>2019</td>
<td></td>
<td><a target="_blank" rel="noopener" href="http://ota-adversarial-examples.selfip.org/">☑️</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://www.usenix.org/system/files/sec20summer_chen-yuxuan_prepub.pdf">Devil’s Whisper: A General Approach for Physical Adversarial Attacks against Commercial Black-box Speech Recognition Devices</a></td>
<td>Y. Chen et al.</td>
<td>USENIX Security</td>
<td>2020</td>
<td><a target="_blank" rel="noopener" href="https://github.com/RiskySignal/Devil-Whisper-Attack">☑️</a></td>
<td><a target="_blank" rel="noopener" href="https://sites.google.com/view/devil-whisper">☑️</a></td>
<td></td>
</tr>
</tbody></table>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/11/18/%E5%9C%A8%E5%8A%A0%E5%AF%86%E6%95%B0%E6%8D%AE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%AD%E7%BB%83/" rel="prev" title="在加密数据上进行神经网络的训练">
                  <i class="fa fa-chevron-left"></i> 在加密数据上进行神经网络的训练
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/01/24/FL%E8%90%BD%E5%9C%B0%E6%A1%86%E6%9E%B6%E8%B0%83%E7%A0%94/" rel="next" title="FL工业框架落地调研">
                  FL工业框架落地调研 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jiqiang Gao</span>
</div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  




  <script src="/js/local-search.js"></script>















  








  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
