[{"title":"Hello World","url":"/2020/11/14/hello-world/","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"hello\"><a href=\"#hello\" class=\"headerlink\" title=\"hello\"></a>hello</h2><h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n"},{"title":"在加密数据上进行神经网络的训练","url":"/2020/11/18/%E5%9C%A8%E5%8A%A0%E5%AF%86%E6%95%B0%E6%8D%AE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%AD%E7%BB%83/","content":"<h1 id=\"在加密数据上进行神经网络的训练\"><a href=\"#在加密数据上进行神经网络的训练\" class=\"headerlink\" title=\"在加密数据上进行神经网络的训练\"></a>在加密数据上进行神经网络的训练</h1><h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>本文介绍一下目前如何使用加密数据进行神经网络的训练，并简要介绍各种应用场景、已有工具框架等内容。</p>\n<h2 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h2><p>当前，基于云的神经网络服务部署逐渐成为主流，在这种情况下，数据和模型由不同方拥有。但是，MLaaS的场景下会产生许多数据隐私问题。举个简单例子来讲，第三方开发了一个深度学习预测模型，对患者的医学数据进行某种疾病的检测。由于法律法规和个人隐私需求的限制，医院无法直接传输明文医学数据给第三方用于模型输入，也不应将检测结果暴露给患者以外的第三方。通过同态加密（HE），医院可以发送加密数据，使得第三方在加密数据上运行模型，而无需透露任何基础信息。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20201118142642144.png?type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Bkc3d6ZA==,size_16,color_FFFFFF,t_70#pic_center\" alt=\"在这里插入图片描述\"></p>\n<p>在过去一段时间，这种基于HE的机器学习方法逐渐成为研究重点，另一种技术主要是安全多方计算（MPC）。HE非常适合使用深度神经网络进行预测的任务。</p>\n<h2 id=\"一些应用场景\"><a href=\"#一些应用场景\" class=\"headerlink\" title=\"一些应用场景\"></a>一些应用场景</h2><p>数据拥有者（DO）和云模型提供者（Cloud）</p>\n<ol>\n<li>加密的数据，未加密的模型：DO将HE加密的数据发送到Cloud。然后，Cloud根据加密数据计算模型以产生加密输出，将输出发送给DO，DO使用私钥对其进行解密。</li>\n<li>未加密的数据，加密的模型：Cloud将已加密的模型发送给DO，然后DO在不现实任何数据的情况下在本地运行模型，以生成加密的输出。DO不会获得任何有关模型的任何信息，并且可以由密钥的所有者（如模型的所有者）解密输出。</li>\n<li>加密数据，加密模型：一个DO或多个DO将数据联合起来输入加密网络进行预测，Cloud返回加密预测结果，需要多个密钥才能解密。类似于联邦学习。</li>\n</ol>\n<p><a href=\"https://medium.com/swlh/faster-neural-networks-on-encrypted-data-with-intel-he-transformer-and-tensorflow-9fdc9eb1a888\">https://medium.com/swlh/faster-neural-networks-on-encrypted-data-with-intel-he-transformer-and-tensorflow-9fdc9eb1a888</a><br>第一个应用场景是最具有代表性的，因为它是MLaaS在同态加密下的直接应用。与MPC相比，HE的优势在于不需要维持通信来进行计算，但是缺点也同样明显，那就是计算量的代价、可计算函数的局限性、同态乘法的误差增长。总体而言，HE方案的主要瓶颈是计算能力，而MPC则是通信。</p>\n<h2 id=\"什么是同态加密\"><a href=\"#什么是同态加密\" class=\"headerlink\" title=\"什么是同态加密\"></a>什么是同态加密</h2><p>同态加密（HE，homomorphic encryption）是密码学里一种特殊的加密模式，同态加密使我们可以将加密后的密文发给任意的第三方进行计算，并且在计算前不需要解密，即：在密文上进行计算。 虽然同态加密的概念最早出现于30年前，但是第一个支持在密文上进行任意运算的<strong>全同态加密</strong>框架出现较晚，在2009年由Craig Gentry提出。</p>\n<p><strong>同态加密的分类</strong></p>\n<ol>\n<li>部分同态加密（<strong>PHE</strong>）指同态加密算法只对加法或乘法（其中一种）有同态的性质。<strong>PHE的优点是原理简单、易实现，缺点是仅支持一种运算（加法或乘法）</strong>。可以应用在<strong>联邦学习</strong>中服务器的聚合操作。</li>\n<li>层次同态加密算法（<strong>LHE</strong>）一般支持有限次数的加法和乘法运算。<strong>LHE的优点是同时支持加法和乘法，并且因为出现时间比PHE晚，所以技术更加成熟、一般效率比FHE要高很多、和PHE效率接近或高于PHE，缺点是支持的计算次数有限。</strong></li>\n<li>全同态加密算法（<strong>FHE</strong>）支持在密文上进行无限次数的、任意类型的计算。<strong>FHE的优点是支持的算子多并且运算次数没有限制，缺点是效率很低，目前还无法支撑大规模的计算。</strong></li>\n<li> 基于格的同态加密算法（<strong>RLWE</strong>）支持有限次数的加法和乘法运算。<strong>RLWE的有点是密文结果较短，效率较与传统方法要好，缺点是该问题在密文中添加了噪声项，在加法特别是乘法期间，噪声项迅速增长，会导致最终无法再解密。</strong></li>\n</ol>\n<p>下面两篇工作是比较知名的用HE来做ML的安全论文。<br><a href=\"https://eprint.iacr.org/2018/073.pdf\">USENIX-18 GAZELLE: A Low Latency Framework for SecureNeural Network Inference</a><br><a href=\"https://eprint.iacr.org/2019/524\">Efficient Multi-Key Homomorphic Encryption with Packed Ciphertexts with Application to Oblivious Neural Network Inference</a></p>\n<h2 id=\"同态加密在机器学习中的应用\"><a href=\"#同态加密在机器学习中的应用\" class=\"headerlink\" title=\"同态加密在机器学习中的应用\"></a>同态加密在机器学习中的应用</h2><h3 id=\"1-联邦学习（PHE）\"><a href=\"#1-联邦学习（PHE）\" class=\"headerlink\" title=\"1.联邦学习（PHE）\"></a>1.联邦学习（PHE）</h3><p>在联邦学习中，多方联合训练模型一般需要交换中间结果，如果直接发送明文的结果可能会有隐私泄露风险。在这种场景下，同态加密就可以发挥很重要的作用。多方直接将中间结果用同态加密算法进行加密，然后发送给第三方进行聚合，再将聚合的结果返回给所有参与者，不仅保证了中间结果没有泄露，还完成了训练任务（第三方可以通过优化系统设计去除）。</p>\n<p>在联邦学习中，因为只需要对中间结果或模型进行聚合，一般使用的同态加密算法为PHE（多见为加法同态加密算法），例如在<a href=\"https://github.com/FederatedAI/FATE\">FATE</a>中使用的Paillier即为加法同态加密算法。为了更好地展示同态加密在联邦学习中的应用，我们在此展示一个同态加密在联邦学习推荐系统中的应用。<img src=\"https://img-blog.csdnimg.cn/20201118155633500.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Bkc3d6ZA==,size_16,color_FFFFFF,t_70#pic_center\" alt=\"在这里插入图片描述\"><br>在传统的推荐系统中，用户需要上传浏览记录、评价信息来实现个性化推荐，但是这些信息均属于个人的隐私数据，直接上传会带来很大的安全隐患。在联邦推荐系统中，每个用户将数据保存在本地，只上传特定的模型梯度。这样虽然避免了隐私数据的直接泄露，但是还是透露了梯度信息给云服务器。同时我们发现，从数学上可以证明，使用连续两次更新的梯度即可反推出用户的评分信息。这种情况下，就必须使用同态加密对用户上传的梯度进行保护，即用户在上传梯度前使用加法同态加密算法对梯度信息进行加密，然后云服务器将所有用户的密文梯度进行聚合（相加），再将更新后的模型返还给各个用户解密，完成训练更新。</p>\n<p>这个框架目前使用的公私钥加密方案是存在问题的，当server和其中一个client进行共谋时，私钥会泄露。因此后续可以采用私钥秘密分享的方法进行设计。</p>\n<h3 id=\"2-密态机器学习（LHE和FHE）\"><a href=\"#2-密态机器学习（LHE和FHE）\" class=\"headerlink\" title=\"2. 密态机器学习（LHE和FHE）\"></a>2. 密态机器学习（LHE和FHE）</h3><p>密态计算中使用的同态加密算法多为LHE和FHE。其实全同态加密研究的初衷，就是为了实现安全的云计算，即对云算力有需求的用户可以将本地的数据全部加密，然后上传到云端，然后云端的服务器即可按照用户指令完成计算，整个过程用户的数据不会泄露给云端，从而完成“绝对安全”的云计算服务。</p>\n<p>但是由于目前FHE效率比较低，所以使用全同态加密进行云计算远远没有达到应用的级别。机器学习在云计算中有着广阔的市场，而机器学习有训练和推理两种需求，训练过程一般数据较多、计算量很大，而推理则数据量相对较小、计算量也小，所以目前研究主要集中在密态下的机器学习推理，并且目前已经有速度比较快的方案 （USENIX-18 GAZELLE）；而密态下的机器学习训练研究稀少，是一个比较难解决的问题。</p>\n<h2 id=\"一些开源的密态机器学习方案实现\"><a href=\"#一些开源的密态机器学习方案实现\" class=\"headerlink\" title=\"一些开源的密态机器学习方案实现\"></a>一些开源的密态机器学习方案实现</h2><ol>\n<li><strong><a href=\"https://github.com/IntelAI/he-transformer\">IntelAI/he-transformer</a>：</strong><br>对加密数据进行本地机器学习，支持多种加密模式，如Microsoft的<a href=\"https://github.com/microsoft/SEAL\">SEAL-CKKS</a>的同态方案和<a href=\"https://github.com/encryptogroup/ABY\">ABY</a>的MPC方案。并有开源实现和论文支持。</li>\n<li><strong><a href=\"https://github.com/facebookresearch/CrypTen\">Facebook/CrypTen</a>：</strong><br>主要是采用了安全多方计算来实现数据隐私保护下的机器学习任务。目前还在原型阶段。</li>\n</ol>\n","categories":["secure ML"]},{"title":"语音对抗攻击","url":"/2020/12/17/res/","content":"<h1 id=\"语音对抗调研\"><a href=\"#语音对抗调研\" class=\"headerlink\" title=\"语音对抗调研\"></a>语音对抗调研</h1><h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>相较于在图像上进行对抗攻击，对语音识别任务进行对抗攻击起步更晚，也更具有挑战性。原因在于语音识别极大依赖于语音信号数据中的频率和时序赖关系，在输入模型识别前需要对语音进行预处理和语音特征提取得到语音频谱图，图像上的对抗攻击可以利用给定可微损失函数的梯度来指导对抗搜索，但是语音上的损失标准一般不可分解，很难用梯度的方法去生成对抗样本。</p>\n<p><img src=\"res/2020-12-16-10-36-41.png\"></p>\n<p>下面说一下针对语音识别系统对抗攻击的几个标志性工作：</p>\n<p>2015年，Vaidya等人首次尝试针对语音识别系统的扰动攻击，在语音识别系统与处理环节中的特征提取步骤修改输入语音信号，生成人耳无法辨别但能被云隐识别系统正确识别的语音信号，但是实际扰动较大，效果并不好。</p>\n<p>2016年，Calini等人提出了“隐藏语音指令”攻击，设计了基于梯度优化的生成对抗扰动的方法，为了在音频信号特征提取后依然保持对抗性，采用了逆语音特征提取的方法反向得到音频信号。但同样容易被人耳感知。</p>\n<p>2017年，zhang等人提出了“海豚音攻击”。为了让攻击不被人耳察觉，将对抗扰动频率提高到了20Khz以上，虽然不容易被人耳察觉，但是很溶剂被过滤和检测，此外，还需要特定设备发射播放得到超声信号。</p>\n<p>2018年，Calini和Wagner在流行的语音识别系统DeepSpeech上生成了实际意义的对抗样本，借鉴了图像分类的C&amp;W攻击方法并在目标函数中使用了深度学习语音识别模型特有的CTC损失函数。使修改后的音频不易被人耳察觉，同时也能使基于深度学习的识别系统错误识别。但是在噪声环境下鲁棒性较差。</p>\n<p>ps：2018年之前的工作不能称为真正意义上的对抗性样本，因为生成的音频对原始语音的扰动太大，人很容易意识到语音被篡改，并且攻击的语音模型不是基于深度学习训练得到的。</p>\n<h2 id=\"深度学习语音识别框架\"><a href=\"#深度学习语音识别框架\" class=\"headerlink\" title=\"深度学习语音识别框架\"></a>深度学习语音识别框架</h2><h3 id=\"1-end-to-end语音识别模型\"><a href=\"#1-end-to-end语音识别模型\" class=\"headerlink\" title=\"1. end-to-end语音识别模型\"></a>1. end-to-end语音识别模型</h3><p>输入一段.wav格式的音频识别步骤：</p>\n<blockquote>\n<p>1）预处理：会进行解码、降噪等操作，把音频分成较短的帧；<br>2）特征提取：从短帧中提取声学特征，常用MFCC特征(梅尔倒谱系数);<br>3）基于模型的预测：将声学特征作为输入数据，生成预测结果，主流系统通常使用RNNs+CTC损失函数模型<br><img src=\"res/2020-12-15-11-00-49.png\"></p>\n</blockquote>\n<p>这里有两个地方需要进行了解:<br>一个是<strong>CTC</strong>函数，是一种声学模型，CTC-Loss函数，在设计语音对抗样本Loss函数时可能需要用到；一个是<strong>MFCC</strong>，了解语音信息的特征提取过程，便于设计对抗生成方法。</p>\n<h3 id=\"2-基于分类的语音系统\"><a href=\"#2-基于分类的语音系统\" class=\"headerlink\" title=\"2. 基于分类的语音系统\"></a>2. 基于分类的语音系统</h3><blockquote>\n<p>1）预处理：同上；<br>2）特征提取：一般用CNNs提取audio-level feature和frame-level feature<br>3）基于模型的预测：将声学特征作为输入数据，生成预测结果，模型通常用CNNs<br><img src=\"res/2020-12-15-17-05-48.png\"></p>\n</blockquote>\n<h3 id=\"3-目前各公司使用的一些语音识别系统：\"><a href=\"#3-目前各公司使用的一些语音识别系统：\" class=\"headerlink\" title=\"3.目前各公司使用的一些语音识别系统：\"></a>3.目前各公司使用的一些语音识别系统：</h3><p><img src=\"res/2020-12-15-11-39-50.png\"></p>\n<h2 id=\"背景知识\"><a href=\"#背景知识\" class=\"headerlink\" title=\"背景知识\"></a>背景知识</h2><h3 id=\"1-CTC\"><a href=\"#1-CTC\" class=\"headerlink\" title=\"1. CTC\"></a>1. CTC</h3><p>CTC是一种RNN的端到端训练方法，可以让RNN直接对序列数据进行学习，而无需事先标注好训练数据中输入序列和输出序列的映射关系。音频数据很难像文本那样进行分割，因此无法直接使用RNN进行训练。</p>\n<blockquote>\n<p>给定输入序列 X={x1,x2,……xT}以及对应的标签数据 Y={y1,y2,……yU}，目的是找到X到Y的一个映射，这种对时序数据进行分类的算法叫做Temporal Classification。</p>\n</blockquote>\n<p>CTC提供了解决方案，对于一个给定的输入序列 X ，CTC给出所有可能的 Y 的输出分布。根据这个分布，我们可以输出最可能的结果或者给出某个输出的概率。 $Y^*=argmax_yP(Y|X)$</p>\n<p><strong>1.1 对齐</strong></p>\n<p>在CTC中，多个输出路径会对应一个输出结果，输入X是”CAT”的语音，输出Y是文本[C,A,T],音频做切割后，每个时间片得到一个输出。因此X和Y之间的映射是多对一的，在对齐时要考虑<strong>去重</strong>和引入<strong>空白字符</strong>。</p>\n<ul>\n<li>HHHEE_LL_LLLOOO    去重</li>\n<li>HE_L_LO            去除空白字符</li>\n<li>HELLO 完成     </li>\n</ul>\n<p><strong>1.2 CTC loss数学推导</strong></p>\n<p>略，太长只过了一遍<br><a href=\"https://www.cnblogs.com/shiyublog/p/10493348.html\">https://www.cnblogs.com/shiyublog/p/10493348.html</a></p>\n<p><strong>1.3 结果搜索</strong></p>\n<p>贪心搜索是选取每一帧预测概率最大的那一项作为结果，此外还有束搜索，和基于动态规划的搜索。</p>\n<h2 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h2><h3 id=\"场景\"><a href=\"#场景\" class=\"headerlink\" title=\"场景\"></a>场景</h3><p><strong>1. speech-to-text</strong></p>\n<table>\n<thead>\n<tr>\n<th>input</th>\n<th>output</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>正常语音+扰动</td>\n<td>目标语义</td>\n</tr>\n<tr>\n<td>正常语音+扰动</td>\n<td>空语义</td>\n</tr>\n<tr>\n<td>随机噪音+扰动</td>\n<td>目标语义</td>\n</tr>\n</tbody></table>\n<p><strong>2. speech commands classification</strong></p>\n<table>\n<thead>\n<tr>\n<th>input</th>\n<th>output</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>正常语音+扰动</td>\n<td>目标分类</td>\n</tr>\n<tr>\n<td>正常语音+扰动</td>\n<td>随机分类</td>\n</tr>\n<tr>\n<td>随机噪音+扰动</td>\n<td>目标分类</td>\n</tr>\n</tbody></table>\n<p>18年之前的工作基本都是基于传统的语音模型（非神经网络）来做的，或是需要生成全新的音频，例如一段音乐隐藏语音指令这种，不能实现类似于图像对抗中与源数据不可区分的效果；</p>\n<blockquote>\n<p><em>Hidden voice commands.<br>Dolphinattack: Inaudible voice commands.<br>Inaudible voice commands.</em> </p>\n</blockquote>\n<p>同时期另一条研究线路能够做到于源数据几乎不可区分的untarget攻击；</p>\n<blockquote>\n<p><em>Crafting adversarial examples for speech paralinguistics applications.<br>Houdini: Fooling deep structured prediction models.</em></p>\n</blockquote>\n<p>2018年Carlini &amp; Wagner实现了针对任意多词句子的语音识别系统构建了对抗样本，但不能在real world有效。同年CommanderSong开发出了在real world有效的对抗样本，但代价是给原始音频引入了明显的扰动。</p>\n<blockquote>\n<p><em>Audio adversarial examples: Targeted attacks on speech-to-text.<br>Commandersong: A systematic approach for practical adversarial voice recognition.</em></p>\n</blockquote>\n<p>此后，一些工作开发了对深度学习ASR系统的攻击，要么在real world中工作，要么不那么明显地被察觉</p>\n<blockquote>\n<p><em>Robust audio adversarial example for a physical attack.<br>Adversarial attacks against automatic speech recognition systems via psychoacoustic hiding.</em></p>\n</blockquote>\n<p>在后面，就是一些将白盒设置转为黑盒设置的一些工作</p>\n<blockquote>\n<p><em>Adversarial blackbox attacks for automatic speech recognition systems using multi-objective genetic optimization.<br>Targeted adversarial examples for black box audio systems.</em></p>\n</blockquote>\n<h3 id=\"具体方法\"><a href=\"#具体方法\" class=\"headerlink\" title=\"具体方法\"></a>具体方法</h3><p>直觉是直接使用图像中生成对抗样本的算法，例如FGSM、DeepFool、PGD等等，但是这些方法在语音对抗样本生成过程中都不好用。因此需要新的算法设计。</p>\n<h4 id=\"1-真正意义上第一个对抗语音工作：Audio-Adversarial-Examples-Targeted-Attacks-on-Speech-to-Text-作者是C-amp-W\"><a href=\"#1-真正意义上第一个对抗语音工作：Audio-Adversarial-Examples-Targeted-Attacks-on-Speech-to-Text-作者是C-amp-W\" class=\"headerlink\" title=\"1. 真正意义上第一个对抗语音工作：Audio Adversarial Examples:Targeted Attacks on Speech-to-Text 作者是C&amp;W\"></a>1. 真正意义上第一个对抗语音工作：Audio Adversarial Examples:Targeted Attacks on Speech-to-Text 作者是C&amp;W</h4><p><a href=\"https://github.com/carlini/audio_adversarial_examples\">https://github.com/carlini/audio_adversarial_examples</a></p>\n<blockquote>\n<p>白盒场景下，针对百度DeepSpeech迭代优化攻击。给定任意音频波形，可以产生99.99%相似的另一个音频，且可以转录为所选择的任何短语。<br>算法：借鉴了图像对抗样本中的C&amp;W方法，将对抗语音生成问题首次转换为了优化问题，并首次在语音对抗样本生成目标函数中引入了深度学习语音识别模型特有的CTC损失函数。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Initial</th>\n<th>Reformulation</th>\n<th>Solve $l_{\\infty}$  without converge</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><img src=\"res/2020-12-15-19-01-45.png\"></td>\n<td><img src=\"res/2020-12-15-19-06-05.png\"></td>\n<td><img src=\"res/2020-12-15-19-21-33.png\"></td>\n</tr>\n</tbody></table>\n<p>在这里设$l(x’,t)=CTC-Loss(x’,t)$，</p>\n<p><strong>Improved loss function：</strong></p>\n<table>\n<thead>\n<tr>\n<th><img src=\"res/2020-12-15-19-46-04.png\"></th>\n<th><img src=\"res/2020-12-15-19-46-40.png\"></th>\n<th><img src=\"res/2020-12-15-19-47-44.png\"></th>\n</tr>\n</thead>\n</table>\n<p>本文在improved loss中说明攻击方法只能在 DeepSpeech 使用 Greedy-Search 的情况下有效。</p>\n<ul>\n<li><strong>Demo</strong></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Status</th>\n<th>Audio</th>\n<th>Transcription</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>original</td>\n<td><audio id=\"audio\" controls=\"\" preload=\"none\"><source id=\"mp3\" src=\"https://nicholas.carlini.com/code/audio_adversarial_examples/adversarial0.wav\"></audio></td>\n<td>okay google browse to evil dot com</td>\n</tr>\n<tr>\n<td>adversarial</td>\n<td><audio id=\"audio\" controls=\"\" preload=\"none\"><source id=\"mp3\" src=\"https://nicholas.carlini.com/code/audio_adversarial_examples/adversarial0.wav\"></audio></td>\n<td>without the dataset the article is useless</td>\n</tr>\n</tbody></table>\n<h4 id=\"2-两阶段优化求解噪声：SirenAttack-Generating-Adversarial-Audio-for-End-to-End-Acoustic-Systems\"><a href=\"#2-两阶段优化求解噪声：SirenAttack-Generating-Adversarial-Audio-for-End-to-End-Acoustic-Systems\" class=\"headerlink\" title=\"2. 两阶段优化求解噪声：SirenAttack: Generating Adversarial Audio for End-to-End Acoustic Systems\"></a>2. 两阶段优化求解噪声：SirenAttack: Generating Adversarial Audio for End-to-End Acoustic Systems</h4><blockquote>\n<p>白盒：第一阶段先利用粒子群算法(PSO)求出粗粒度的噪声$\\delta$,第二阶段再利用CTC-loss反馈的梯度信息使用Fooling Gradient方法对其矫正求出更精确的$\\delta$。<br>   黑盒：由于没有loss信息，所以在第一阶段引入模型置信度量，引导粒子群向更优方向迭代，效果有限。</p>\n</blockquote>\n<p>亮点：涉及到了黑盒、计算效率高生成时间段、攻击测试了多个主流的语音识别模型</p>\n<h4 id=\"3-设计新的代理损失函数：Houdini-Fooling-Deep-Structured-Visual-and-Speech-Recognition-Models-with-Adversarial-Examples\"><a href=\"#3-设计新的代理损失函数：Houdini-Fooling-Deep-Structured-Visual-and-Speech-Recognition-Models-with-Adversarial-Examples\" class=\"headerlink\" title=\"3. 设计新的代理损失函数：Houdini: Fooling Deep Structured Visual and Speech Recognition Models with Adversarial Examples\"></a>3. 设计新的代理损失函数：Houdini: Fooling Deep Structured Visual and Speech Recognition Models with Adversarial Examples</h4><p>解决了对抗样本生成中评价指标存在组合及不可谓的问题，如语音识别中常用word error rate来评价，其就是不可微的。文章中提到，虽然CTC针对语音识别任务是一种可微的代理损失函数，但是针对其他结构性任务（如语义分割、姿态估计等）并没有一致性保证。本文实际是提出了一种针对类似不可微问题下生成对抗样本的框架。</p>\n<p>文章提出了一种Houdini代理损失函数，可以用来针对结构性任务生成对抗样本：<br><img src=\"res/2020-12-16-11-16-23.png\"></p>\n<p>文章中还对基于Houdini和CTC两种损失函数生成的对抗样本进行了比较，结果显示Houdini要优于CTC，但是target攻击效果并不好。 ps:由于遇到MFC层反向传播的困难，因此攻击只能生成音谱对抗数据，不能直接生成audio，工作1解决了这个问题。</p>\n<h4 id=\"4-不可察觉-鲁棒：Imperceptible-Robust-and-Targeted-Adversarial-Examples-for-Automatic-Speech-Recognition\"><a href=\"#4-不可察觉-鲁棒：Imperceptible-Robust-and-Targeted-Adversarial-Examples-for-Automatic-Speech-Recognition\" class=\"headerlink\" title=\"4. 不可察觉+鲁棒：Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition\"></a>4. 不可察觉+鲁棒：Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition</h4><ul>\n<li>白盒、有目标的、针对端到端LAS模型的对抗攻击算法；</li>\n<li>心里掩蔽效应</li>\n<li>模拟房间声学响应</li>\n</ul>\n<p>亮点在于优化语音对抗输入使其对人耳不可分辨，且更加Robust，首次在real world中产生有效攻击。提出了非基于$l_p$的对抗样本构造方法。</p>\n<p>不可察觉：文中未使用$l_p$失真度量，而是依赖于构建<strong>心理学模型</strong>使得对抗语音难以察觉：<strong>频率掩蔽</strong>通过使用另外一种充当“掩蔽器”的信号对对抗性样本进行掩护，实质是在人类听不到音频区域添加对抗扰动。优化分为两阶段，首先寻找一个相对较小的的扰动欺骗网络（和C&amp;W工作相同），再去优化对抗样本使其不易察觉。</p>\n<p>物理世界可用：考虑在训练时引入随机房间环境模拟器，考虑现实环境中的影响，实验只在模拟环境下有效。带混响的优化。</p>\n<p>最后算法将两个目标结合，设计了优化损失函数。</p>\n<h4 id=\"5-白盒鲁棒：Robust-Audio-Adversarial-Example-for-a-Physical-Attack\"><a href=\"#5-白盒鲁棒：Robust-Audio-Adversarial-Example-for-a-Physical-Attack\" class=\"headerlink\" title=\"5. 白盒鲁棒：Robust Audio Adversarial Example for a Physical Attack\"></a>5. 白盒鲁棒：Robust Audio Adversarial Example for a Physical Attack</h4><p><a href=\"https://github.com/hiromu/robust_audio_ae\">https://github.com/hiromu/robust_audio_ae</a></p>\n<p>亮点：引入脉冲响应，首次实现了pysical下的对抗样本攻击，直接思路就是讲环境带来的扰动提前考虑进来，用到了三个技术：</p>\n<ul>\n<li>Band-pass Filter：麦克风会去除环境中的一些杂音，若对抗扰动超出范围，则会被剪切，因此在损失函数中讲对抗扰动固定在不会被剪切的一个范围。</li>\n<li>Impulse Response：将环境中的脉冲响应考虑进损失函数，增强对抗语音在使用中对混响的鲁棒性。</li>\n<li>White Gaussian Noise：模拟环境中许多自然产生的背景噪声</li>\n</ul>\n<h4 id=\"6-鲁棒：Towards-Resistant-Audio-Adversarial-Examples\"><a href=\"#6-鲁棒：Towards-Resistant-Audio-Adversarial-Examples\" class=\"headerlink\" title=\"6. 鲁棒：Towards Resistant Audio Adversarial Examples\"></a>6. 鲁棒：Towards Resistant Audio Adversarial Examples</h4><p>考虑实际场景下播放器和麦克风之间距离引起的位移偏差，在优化对抗数据时加入偏差因素，使得最终的对抗语音具有较好的鲁棒性。</p>\n<h4 id=\"7-黑盒：Targeted-Adversarial-Examples-for-Black-Box-Audio-Systems\"><a href=\"#7-黑盒：Targeted-Adversarial-Examples-for-Black-Box-Audio-Systems\" class=\"headerlink\" title=\"7. 黑盒：Targeted Adversarial Examples for Black Box Audio Systems\"></a>7. 黑盒：Targeted Adversarial Examples for Black Box Audio Systems</h4><p>code：<a href=\"https://github.com/rtaori/Black-Box-Audio\">https://github.com/rtaori/Black-Box-Audio</a></p>\n<ul>\n<li>黑盒、有目标的攻击DeepSpeech的对抗攻击算法</li>\n<li>两阶段方法：遗传（改进引入Momentum mutation）+梯度估计</li>\n<li>问题：出现了query次数巨大的问题，适用场景有限</li>\n</ul>\n<h4 id=\"8-Cocaine-Noodles-Exploiting-the-Gap-between-Human-and-Machine-Speech-Recognition\"><a href=\"#8-Cocaine-Noodles-Exploiting-the-Gap-between-Human-and-Machine-Speech-Recognition\" class=\"headerlink\" title=\"8. Cocaine Noodles: Exploiting the Gap between Human and Machine Speech Recognition\"></a>8. Cocaine Noodles: Exploiting the Gap between Human and Machine Speech Recognition</h4><ul>\n<li>攻击特征模块</li>\n<li>思路简单，提取MFCC特征（这个过程会丢失一些语音信息），然后把MFCC特征逆转为语音信号</li>\n<li>算法描述不清晰，如何对MFCC逆转没过多提及。</li>\n</ul>\n<p><img src=\"res/2020-12-17-17-32-37.png\"></p>\n<h4 id=\"9-黑盒-amp-白盒：Hidden-Voice-Commands\"><a href=\"#9-黑盒-amp-白盒：Hidden-Voice-Commands\" class=\"headerlink\" title=\"9. 黑盒&amp;白盒：Hidden Voice Commands\"></a>9. 黑盒&amp;白盒：Hidden Voice Commands</h4><p>黑盒下生成一段无关的音频，其中隐藏有语音指令，本质上还不能称之为对抗语音，因为生成的音频不是不可察觉的。</p>\n<ul>\n<li>是对Cocaine Noodles的完善</li>\n<li>攻击特征提取模块</li>\n<li>使用梯度下降算法攻击GMM-HMM模型</li>\n<li>从这篇开始语音对抗有了比较清晰的思路，calini还是很有经验的。</li>\n</ul>\n<p><img src=\"res/2020-12-16-20-14-15.png\"></p>\n<p>比较关键的是MFCC parameter和inverse MFCC这两步。计算MFCC然后逆转为时域信号的过程，能够从理论上保留<strong>语音识别算法关注的特征，而抹除不想管的语音特征</strong>，而抹除的这部分特征又很可能是对人的听觉影响是很大的，导致人无法听清对抗样本。</p>\n<h4 id=\"10-黑盒：“Did-you-hear-that-Adversarial-Examples-Against-Automatic-Speech-Recognition-”\"><a href=\"#10-黑盒：“Did-you-hear-that-Adversarial-Examples-Against-Automatic-Speech-Recognition-”\" class=\"headerlink\" title=\"10. 黑盒：“Did you hear that? Adversarial Examples Against Automatic Speech Recognition,”\"></a>10. 黑盒：“Did you hear that? Adversarial Examples Against Automatic Speech Recognition,”</h4><p><a href=\"https://github.com/nesl/adversarial_audio\">https://github.com/nesl/adversarial_audio</a></p>\n<p>场景是语音分类场景下的对抗样本攻击，攻击目标是ASR，指出语音对抗样本无法适用基于梯度的优化迭代方法，使用了<strong>遗传算法</strong>。</p>\n<img src=\"res/2020-12-17-13-29-34.png\" width=\"60%\" height=\"60%\">\n\n<h4 id=\"11-不可听超声波蕴含语义信息：DolphinAttack-Inaudible-Voice-Commands\"><a href=\"#11-不可听超声波蕴含语义信息：DolphinAttack-Inaudible-Voice-Commands\" class=\"headerlink\" title=\"11. 不可听超声波蕴含语义信息：DolphinAttack: Inaudible Voice Commands\"></a>11. 不可听超声波蕴含语义信息：DolphinAttack: Inaudible Voice Commands</h4><p>海豚音攻击：利用麦克风的非线性来用高于20 kHz的超声波调节基带音频信号，可以隐藏转录。让正常的语音隐藏到高频波段中，从而让其无法被听到。</p>\n<p><strong>实质上是利用了麦克风的非线性漏洞，使得高频信号采样后出现额外的低频分量</strong></p>\n<h4 id=\"12-心理声学模型：Adversarial-Attacks-Against-Automatic-Speech-Recognition-Systems-via-Psychoacoustic-Hiding\"><a href=\"#12-心理声学模型：Adversarial-Attacks-Against-Automatic-Speech-Recognition-Systems-via-Psychoacoustic-Hiding\" class=\"headerlink\" title=\"12. 心理声学模型：Adversarial Attacks Against Automatic Speech Recognition Systems via Psychoacoustic Hiding\"></a>12. 心理声学模型：Adversarial Attacks Against Automatic Speech Recognition Systems via Psychoacoustic Hiding</h4><p>介绍了一种基于心理声学隐藏的攻击ASR系统的新型对抗样本。利用如MP3编码中的心理声学建模，以减少可察觉的噪音。</p>\n<ul>\n<li>白盒、有目标的、针对DNN-HMM模型的对抗攻击算法</li>\n<li>首次提出使用升学掩蔽效应</li>\n</ul>\n<p><img src=\"res/2020-12-17-17-03-20.png\"></p>\n<p>example：黑色为1Khz处60db的能量掩蔽曲线</p>\n<h4 id=\"13-音乐-指令隐藏：CommanderSong-A-Systematic-Approach-for-Practical-Adversarial-Voice-Recognition\"><a href=\"#13-音乐-指令隐藏：CommanderSong-A-Systematic-Approach-for-Practical-Adversarial-Voice-Recognition\" class=\"headerlink\" title=\"13 音乐+指令隐藏：CommanderSong: A Systematic Approach for Practical Adversarial Voice Recognition\"></a>13 音乐+指令隐藏：CommanderSong: A Systematic Approach for Practical Adversarial Voice Recognition</h4><p>在歌曲中加入语音命令，通过播放歌曲实施攻击</p>\n<h4 id=\"14-Practical-Hidden-Voice-Attacks-against-Speech-and-Speaker-Recognition-Systems\"><a href=\"#14-Practical-Hidden-Voice-Attacks-against-Speech-and-Speaker-Recognition-Systems\" class=\"headerlink\" title=\"14. Practical Hidden Voice Attacks against Speech and Speaker Recognition Systems\"></a>14. Practical Hidden Voice Attacks against Speech and Speaker Recognition Systems</h4><ul>\n<li>Hidden voice的黑盒扩展，将正常语音模糊化，攻击特征提取模块</li>\n<li>体现出语音攻击在物理、黑盒环境下的挑战是很大的</li>\n</ul>\n<h4 id=\"15-Hear-“No-Evil”-See-“Kenansville”-Efficient-and-Transferable-Black-Box-Attacks-on-Speech-Recognition-and-Voice-Identification-Systems\"><a href=\"#15-Hear-“No-Evil”-See-“Kenansville”-Efficient-and-Transferable-Black-Box-Attacks-on-Speech-Recognition-and-Voice-Identification-Systems\" class=\"headerlink\" title=\"15. Hear “No Evil”, See “Kenansville”: Efficient and Transferable Black-Box Attacks on Speech Recognition and Voice Identification Systems.\"></a>15. Hear “No Evil”, See “Kenansville”: Efficient and Transferable Black-Box Attacks on Speech Recognition and Voice Identification Systems.</h4><p><a href=\"https://github.com/kwarren9413/kenansville_attack\">https://github.com/kwarren9413/kenansville_attack</a></p>\n<ul>\n<li>声称能做到近实时、黑盒、可迁移欺骗ASR，对抗语音几乎不会误导人耳，但是会产生非目标识别错误</li>\n<li>可以大大减少黑盒攻击下query的次数</li>\n<li>不是基于梯度来做的</li>\n</ul>\n<p><img src=\"res/2020-12-17-19-48-34.png\"></p>\n<p>signal decomposition用的是DFT or SSA，没用MFCC，步骤也比较简单，就是设置阈值对信号进行截断，在不影响人耳识别的情况下，尽可能欺骗ASR。由于不涉及梯度，所以可以看作是黑盒的。</p>\n<h4 id=\"16-The-Faults-in-our-ASRs-An-Overview-of-Attacks-against-Automatic-Speech-Recognition-and-Speaker-Identification-Systems\"><a href=\"#16-The-Faults-in-our-ASRs-An-Overview-of-Attacks-against-Automatic-Speech-Recognition-and-Speaker-Identification-Systems\" class=\"headerlink\" title=\"16. The Faults in our ASRs: An Overview of Attacks against Automatic Speech Recognition and Speaker Identification Systems\"></a>16. The Faults in our ASRs: An Overview of Attacks against Automatic Speech Recognition and Speaker Identification Systems</h4><blockquote>\n<p>2021年 S&amp;P的一篇综述：（Hadi Abdullah在audio攻击有若干工作）下图是总结了已有攻击的各个维度的对比。</p>\n</blockquote>\n<p><img src=\"res/2020-12-17-17-45-53.png\"></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>对语音识别系统做对抗样本攻击，首先要了解语音模型的识别流程，重点是特征提取的CTC步骤，然后在黑盒下要注意使用遗传算法，同时，要做到现实可用且不可察觉两点要求。基于上述的攻击目标，目前的工作基本只能完成其中几项，且实验条件苛刻。   </p>\n<p><img src=\"res/%E8%AF%AD%E9%9F%B3%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB.png\"></p>\n<h2 id=\"一些开源的实现\"><a href=\"#一些开源的实现\" class=\"headerlink\" title=\"一些开源的实现\"></a>一些开源的实现</h2><h3 id=\"Audio-Adversarial-Examples-Paper-List\"><a href=\"#Audio-Adversarial-Examples-Paper-List\" class=\"headerlink\" title=\"Audio Adversarial Examples Paper List\"></a>Audio Adversarial Examples Paper List</h3><table>\n<thead>\n<tr>\n<th>Title</th>\n<th>Authors</th>\n<th>Publication</th>\n<th>Year</th>\n<th>Code</th>\n<th>Demo</th>\n<th>Presentation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><a href=\"http://arxiv.org/abs/1708.07238\">Inaudible Voice Commands</a></td>\n<td>L. Song et al.</td>\n<td>CCS</td>\n<td>2017</td>\n<td><a href=\"https://github.com/lwsong/inaudible-voice-commands\">☑️</a></td>\n<td><a href=\"https://www.youtube.com/watch?v=wF-DuVkQNQQ\">☑️</a></td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"http://arxiv.org/abs/1801.01944\">Audio Adversarial Examples: Targeted Attacks on Speech-to-Text</a></td>\n<td>N. Carlini et al.</td>\n<td>DLS</td>\n<td>2018</td>\n<td><a href=\"https://github.com/carlini/audio_adversarial_examples\">☑️</a></td>\n<td><a href=\"https://nicholas.carlini.com/code/audio_adversarial_examples/\">☑️</a></td>\n<td><a href=\"https://www.youtube.com/watch?v=Ho5jLKfoKSA\">☑️</a></td>\n</tr>\n<tr>\n<td><a href=\"http://arxiv.org/abs/1805.11852\">ADAGIO: Interactive Experimentation with Adversarial Attack and Defense for Audio</a></td>\n<td>N. Das et al.</td>\n<td>ECML-PKDD</td>\n<td>2018</td>\n<td></td>\n<td><a href=\"https://youtu.be/0W2BKMwSfVQ\">☑️</a></td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://www.usenix.org/conference/usenixsecurity18/presentation/yuan-xuejing\">CommanderSong: A Systematic Approach for Practical Adversarial Voice Recognition</a></td>\n<td>X. Yuan et al.</td>\n<td>USENIX Security</td>\n<td>2018</td>\n<td></td>\n<td></td>\n<td><a href=\"https://www.usenix.org/conference/usenixsecurity18/presentation/yuan-xuejing\">☑️</a></td>\n</tr>\n<tr>\n<td><a href=\"http://arxiv.org/abs/1811.01312\">Adversarial Black-Box Attacks for Automatic Speech Recognition Systems Using Multi-Objective Genetic Optimization</a></td>\n<td>S. Khare et al.</td>\n<td>Interspeech</td>\n<td>2019</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"http://arxiv.org/abs/1808.05665\">Adversarial Attacks Against Automatic Speech Recognition Systems via Psychoacoustic Hiding</a></td>\n<td>L. Schönherr et al.</td>\n<td>NDSS</td>\n<td>2019</td>\n<td><a href=\"https://github.com/rub-ksv/adversarialattacks\">☑️</a></td>\n<td><a href=\"https://adversarial-attacks.net/\">☑️</a></td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"http://arxiv.org/abs/1810.11793\">Robust Audio Adversarial Example for a Physical Attack</a></td>\n<td>H. Yakura et al.</td>\n<td>IJCAI</td>\n<td>2019</td>\n<td><a href=\"https://github.com/hiromu/robust_audio_ae\">☑️</a></td>\n<td><a href=\"https://yumetaro.info/projects/audio-ae/\">☑️</a></td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"http://arxiv.org/abs/1809.10875\">Characterizing Audio Adversarial Examples Using Temporal Dependency</a></td>\n<td>Z. Yang et al.</td>\n<td>ICLR</td>\n<td>2019</td>\n<td><a href=\"https://github.com/AI-secure/Characterizing-Audio-Adversarial-Examples-using-Temporal-Dependency\">☑️</a></td>\n<td><a href=\"https://www.ibm.com/blogs/research/2019/05/audio-adversarial-attacks/\">☑️</a></td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"http://arxiv.org/abs/1904.05734\">Practical Hidden Voice Attacks against Speech and Speaker Recognition Systems</a></td>\n<td>H. Abdullah et al.</td>\n<td>NDSS</td>\n<td>2019</td>\n<td></td>\n<td><a href=\"https://sites.google.com/view/transcript-evasion\">☑️</a></td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"http://arxiv.org/abs/1910.05262\">Hear ‘No Evil’, See ‘Kenansville’: Efficient and Transferable Black-Box Attacks on Speech Recognition and Voice Identification Systems</a></td>\n<td>H. Abdullah et al.</td>\n<td>arXiv</td>\n<td>2019</td>\n<td><a href=\"https://github.com/hamzayacoob/VPSesAttacks\">☑️</a></td>\n<td><a href=\"https://sites.google.com/view/transcript-evasion\">☑️</a></td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"http://arxiv.org/abs/1901.07846\">SirenAttack: Generating Adversarial Audio for End-to-End Acoustic Systems</a></td>\n<td>T. Du et al.</td>\n<td>NDSS</td>\n<td>2019</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"http://arxiv.org/abs/1901.10300\">Towards Weighted-Sampling Audio Adversarial Example Attack</a></td>\n<td>X. Liu et al.</td>\n<td>AAAI</td>\n<td>2019</td>\n<td></td>\n<td><a href=\"https://sites.google.com/view/audio-adversarial-examples\">☑️</a></td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"http://arxiv.org/abs/1905.03828\">Universal Adversarial Perturbations for Speech Recognition Systems</a></td>\n<td>P. Neekharaet al.</td>\n<td>Interspeech</td>\n<td>2019</td>\n<td></td>\n<td><a href=\"https://universal-audio-perturbation.herokuapp.com/index.html\">☑️</a></td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"http://arxiv.org/abs/1903.10346\">Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition</a></td>\n<td>Y. Qin et al.</td>\n<td>ICML</td>\n<td>2019</td>\n<td><a href=\"https://github.com/tensorflow/cleverhans/tree/master/examples/adversarial_asr\">☑️</a></td>\n<td><a href=\"http://cseweb.ucsd.edu/~yaq007/imperceptible-robust-adv.html\">☑️</a></td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"http://arxiv.org/abs/1908.01551\">Imperio: Robust Over-the-Air Adversarial Examples for Automatic Speech Recognition Systems</a></td>\n<td>L. Schönherr et al.</td>\n<td>arXiv</td>\n<td>2019</td>\n<td></td>\n<td><a href=\"http://ota-adversarial-examples.selfip.org/\">☑️</a></td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://www.usenix.org/system/files/sec20summer_chen-yuxuan_prepub.pdf\">Devil’s Whisper: A General Approach for Physical Adversarial Attacks against Commercial Black-box Speech Recognition Devices</a></td>\n<td>Y. Chen et al.</td>\n<td>USENIX Security</td>\n<td>2020</td>\n<td><a href=\"https://github.com/RiskySignal/Devil-Whisper-Attack\">☑️</a></td>\n<td><a href=\"https://sites.google.com/view/devil-whisper\">☑️</a></td>\n<td></td>\n</tr>\n</tbody></table>\n","categories":["secure ML"]},{"title":"111","url":"/2020/12/17/111/","content":"<p><img src=\"2020-12-15-11-00-49.png\"></p>\n"}]